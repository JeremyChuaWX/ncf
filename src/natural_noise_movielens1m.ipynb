{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing necessary libraries\n",
    "from surprise import NMF\n",
    "from surprise import SVD\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Load Data\n",
    "ml1m_dir = 'ratings.dat'\n",
    "ml1m_rating = pd.read_csv(ml1m_dir, sep='::', header=None, names=['uid', 'mid', 'rating', 'timestamp'],  engine='python')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reindex and cleaning data to accurate format\n",
    "user_id = ml1m_rating[['uid']].drop_duplicates().reindex()\n",
    "user_id['userId'] = np.arange(len(user_id))\n",
    "ml1m_rating = pd.merge(ml1m_rating, user_id, on=['uid'], how='left')\n",
    "item_id = ml1m_rating[['mid']].drop_duplicates()\n",
    "item_id['itemId'] = np.arange(len(item_id))\n",
    "ml1m_rating = pd.merge(ml1m_rating, item_id, on=['mid'], how='left')\n",
    "ml1m_rating = ml1m_rating[['userId', 'itemId', 'rating', 'timestamp']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the timestamp column to a datetime object\n",
    "ml1m_rating['date'] = pd.to_datetime(ml1m_rating['timestamp'], unit='s')  # Assuming Unix timestamp in seconds\n",
    "# Extract the date and create a new column\n",
    "ml1m_rating['date'] = ml1m_rating['date'].dt.date\n",
    "df = ml1m_rating\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>itemId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "      <td>2000-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "      <td>2000-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "      <td>2000-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "      <td>2000-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "      <td>2001-01-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000204</th>\n",
       "      <td>6039</td>\n",
       "      <td>772</td>\n",
       "      <td>1</td>\n",
       "      <td>956716541</td>\n",
       "      <td>2000-04-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000205</th>\n",
       "      <td>6039</td>\n",
       "      <td>1106</td>\n",
       "      <td>5</td>\n",
       "      <td>956704887</td>\n",
       "      <td>2000-04-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000206</th>\n",
       "      <td>6039</td>\n",
       "      <td>365</td>\n",
       "      <td>5</td>\n",
       "      <td>956704746</td>\n",
       "      <td>2000-04-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000207</th>\n",
       "      <td>6039</td>\n",
       "      <td>152</td>\n",
       "      <td>4</td>\n",
       "      <td>956715648</td>\n",
       "      <td>2000-04-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000208</th>\n",
       "      <td>6039</td>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "      <td>956715569</td>\n",
       "      <td>2000-04-26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000209 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         userId  itemId  rating  timestamp        date\n",
       "0             0       0       5  978300760  2000-12-31\n",
       "1             0       1       3  978302109  2000-12-31\n",
       "2             0       2       3  978301968  2000-12-31\n",
       "3             0       3       4  978300275  2000-12-31\n",
       "4             0       4       5  978824291  2001-01-06\n",
       "...         ...     ...     ...        ...         ...\n",
       "1000204    6039     772       1  956716541  2000-04-26\n",
       "1000205    6039    1106       5  956704887  2000-04-25\n",
       "1000206    6039     365       5  956704746  2000-04-25\n",
       "1000207    6039     152       4  956715648  2000-04-26\n",
       "1000208    6039      26       4  956715569  2000-04-26\n",
       "\n",
       "[1000209 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What the current data looks like\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create columns for different ypes of users\n",
    "df['Weak_user'] = np.nan\n",
    "df['Average_user'] = np.nan\n",
    "df['Strong_user'] = np.nan\n",
    "df['Weak_item'] = np.nan\n",
    "df['Average_item'] = np.nan\n",
    "df['Strong_item'] = np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the thresholds for defining weak/average/strong users, and weak/average/strong items for each rating\n",
    "# Rmin/Rmax - Min/Max of all ratings\n",
    "# T1_u/T2_u - Threshold for weak user(Below T1_u) and strong user(Above T2_u); Average user(In between)\n",
    "# T1_i/T2_i - Threshold for weak item(Below T1_u) and strong item(Above T2_u); Average item(In between)\n",
    "# T1/T2     -\n",
    "Rmin = df['rating'].min()  #\n",
    "Rmax = df['rating'].max()  #\n",
    "T1_u = Rmin + round((1/3) * (Rmax - Rmin)) #\n",
    "T2_u = Rmax - round((1/3) * (Rmax - Rmin))#\n",
    "T1_i = Rmin + round((1/3) * (Rmax - Rmin))#\n",
    "T2_i = Rmax - round((1/3) * (Rmax - Rmin))#\n",
    "T1 =   Rmin + round((1/3) * (Rmax - Rmin))\n",
    "T2 =  Rmax - round((1/3) * (Rmax - Rmin))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\chews\\Downloads\\BT4222 Code\\natural_noise_movielens1m.ipynb Cell 7\u001b[0m line \u001b[0;36m9\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/chews/Downloads/BT4222%20Code/natural_noise_movielens1m.ipynb#W6sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     df\u001b[39m.\u001b[39mloc[index,\u001b[39m'\u001b[39m\u001b[39mAverage_user\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/chews/Downloads/BT4222%20Code/natural_noise_movielens1m.ipynb#W6sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/chews/Downloads/BT4222%20Code/natural_noise_movielens1m.ipynb#W6sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     df\u001b[39m.\u001b[39mloc[index,\u001b[39m'\u001b[39m\u001b[39mStrong_user\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chews/Downloads/BT4222%20Code/natural_noise_movielens1m.ipynb#W6sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mif\u001b[39;00m user_rating \u001b[39m<\u001b[39m T1_i:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chews/Downloads/BT4222%20Code/natural_noise_movielens1m.ipynb#W6sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     df\u001b[39m.\u001b[39mloc[index,\u001b[39m'\u001b[39m\u001b[39mWeak_item\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\chews\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:818\u001b[0m, in \u001b[0;36m_LocationIndexer.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    815\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_valid_setitem_indexer(key)\n\u001b[0;32m    817\u001b[0m iloc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39miloc\u001b[39m\u001b[39m\"\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39miloc\n\u001b[1;32m--> 818\u001b[0m iloc\u001b[39m.\u001b[39;49m_setitem_with_indexer(indexer, value, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n",
      "File \u001b[1;32mc:\\Users\\chews\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1795\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer\u001b[1;34m(self, indexer, value, name)\u001b[0m\n\u001b[0;32m   1792\u001b[0m \u001b[39m# align and set the values\u001b[39;00m\n\u001b[0;32m   1793\u001b[0m \u001b[39mif\u001b[39;00m take_split_path:\n\u001b[0;32m   1794\u001b[0m     \u001b[39m# We have to operate column-wise\u001b[39;00m\n\u001b[1;32m-> 1795\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_setitem_with_indexer_split_path(indexer, value, name)\n\u001b[0;32m   1796\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1797\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setitem_single_block(indexer, value, name)\n",
      "File \u001b[1;32mc:\\Users\\chews\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1888\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer_split_path\u001b[1;34m(self, indexer, value, name)\u001b[0m\n\u001b[0;32m   1884\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1885\u001b[0m \n\u001b[0;32m   1886\u001b[0m     \u001b[39m# scalar value\u001b[39;00m\n\u001b[0;32m   1887\u001b[0m     \u001b[39mfor\u001b[39;00m loc \u001b[39min\u001b[39;00m ilocs:\n\u001b[1;32m-> 1888\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_setitem_single_column(loc, value, pi)\n",
      "File \u001b[1;32mc:\\Users\\chews\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1992\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_single_column\u001b[1;34m(self, loc, value, plane_indexer)\u001b[0m\n\u001b[0;32m   1988\u001b[0m         value \u001b[39m=\u001b[39m value[pi]\n\u001b[0;32m   1989\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1990\u001b[0m     \u001b[39m# set value into the column (first attempting to operate inplace, then\u001b[39;00m\n\u001b[0;32m   1991\u001b[0m     \u001b[39m#  falling back to casting if necessary)\u001b[39;00m\n\u001b[1;32m-> 1992\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobj\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mcolumn_setitem(loc, plane_indexer, value)\n\u001b[0;32m   1993\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_clear_item_cache()\n\u001b[0;32m   1994\u001b[0m     \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\chews\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py:1392\u001b[0m, in \u001b[0;36mBlockManager.column_setitem\u001b[1;34m(self, loc, idx, value, inplace)\u001b[0m\n\u001b[0;32m   1390\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1391\u001b[0m     new_mgr \u001b[39m=\u001b[39m col_mgr\u001b[39m.\u001b[39msetitem((idx,), value)\n\u001b[1;32m-> 1392\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miset(loc, new_mgr\u001b[39m.\u001b[39;49m_block\u001b[39m.\u001b[39;49mvalues, inplace\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\chews\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py:1259\u001b[0m, in \u001b[0;36mBlockManager.iset\u001b[1;34m(self, loc, value, inplace)\u001b[0m\n\u001b[0;32m   1257\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_clear_reference_block(blkno_l)\n\u001b[0;32m   1258\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1259\u001b[0m         blk\u001b[39m.\u001b[39;49mset_inplace(blk_locs, value_getitem(val_locs))\n\u001b[0;32m   1260\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1261\u001b[0m     unfit_mgr_locs\u001b[39m.\u001b[39mappend(blk\u001b[39m.\u001b[39mmgr_locs\u001b[39m.\u001b[39mas_array[blk_locs])\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Classify users and items into Weak/Average/Strong respectively  for each rating\n",
    "for index, row in df.iterrows():\n",
    "    user_rating = row['rating']\n",
    "    if movie_rating < T1_u:\n",
    "        df.loc[index,'Weak_movie'] = 1\n",
    "    elif T1_u <= user_rating < T2_u:\n",
    "        df.loc[index,'Average_user'] = 1\n",
    "    else:\n",
    "        df.loc[index,'Strong_user'] = 1\n",
    "\n",
    "    if user_rating < T1_i:\n",
    "        df.loc[index,'Weak_item'] = 1\n",
    "    elif T1_i <= user_rating < T2_i:\n",
    "        df.loc[index,'Average_item'] = 1\n",
    "    else:\n",
    "        df.loc[index,'Strong_item'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the userId and itemId columns to user_id and movie_id respectively(To better fit the code)\n",
    "df = df.rename(columns={'userId': 'user_id', 'itemId': 'movie_id'})\n",
    "\n",
    "# Create 2 separate dataframes:\n",
    "# user - Containd userid and information on whether the user is weak/average/strong\n",
    "# movie - Containd movieid and information on whether the movie is weak/average/strong\n",
    "user = df[[\"user_id\",\"Weak_user\",\"Average_user\",\"Strong_user\"]]\n",
    "movie = df[[\"movie_id\",\"Weak_item\",\"Average_item\",\"Strong_item\"]]\n",
    "\n",
    "# For each user, find how many ratings there are in which the user is considered a weak user, average user, and a strong user respectively\n",
    "user = user.groupby(\"user_id\").agg({\n",
    "    'Weak_user': 'sum',\n",
    "    'Average_user': 'sum',\n",
    "    'Strong_user': 'sum'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that classifies each user into weak/average/strong user \n",
    "# Eg If for a user has 10 ratings, and 6 of which considers the user weak, 2 of whicg strong, and the remaining 2 weak.\n",
    "# Then 6 > 2+2, and hence the user is considered weak\n",
    "def classify_user(row):\n",
    "    weak_count = row['Weak_user']\n",
    "    average_count = row['Average_user']\n",
    "    strong_count = row['Strong_user']\n",
    "\n",
    "    if weak_count >= strong_count + average_count:\n",
    "        return 0\n",
    "    elif average_count >= strong_count + weak_count:\n",
    "        return 1\n",
    "    elif strong_count >= average_count + weak_count:\n",
    "        return 2\n",
    "    else:\n",
    "        return -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify user as defined in function above \n",
    "user['User_Classification'] = user.apply(classify_user, axis=1)\n",
    "user.reset_index(inplace=True)\n",
    "user = user[['user_id',\"User_Classification\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the classification for each user into the original df dataframe \n",
    "df = df[[\"movie_id\",\"user_id\",\"rating\",\"date\"]].merge(user,how=\"left\",on=\"user_id\")\n",
    "del user\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each movie, find how many ratings there are in which the movie is considered a weak movie, average movie, and a strong movie respectively\n",
    "movie = movie.groupby(\"movie_id\").agg({\n",
    "    'Weak_item': 'sum',\n",
    "    'Average_item': 'sum',\n",
    "    'Strong_item': 'sum'\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that classifies each movie into weak/average/strong movie\n",
    "# Eg If for a movie has 10 ratings, and 6 of which considers the movie weak, 2 of which strong, and the remaining 2 weak.\n",
    "# Then 6 > 2+2, and hence the movie is considered weak\n",
    "def classify_item(row):\n",
    "    weak_count = row['Weak_item']\n",
    "    average_count = row['Average_item']\n",
    "    strong_count = row['Strong_item']\n",
    "\n",
    "    if weak_count >= strong_count + average_count:\n",
    "        return 0\n",
    "    elif average_count >= strong_count + weak_count:\n",
    "        return 1\n",
    "    elif strong_count >= average_count + weak_count:\n",
    "        return 2\n",
    "    else:\n",
    "        return -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify each movie as defined in function above \n",
    "movie['Item_Classification'] = movie.apply(classify_item, axis=1)\n",
    "movie.reset_index(inplace=True)\n",
    "movie = movie[['movie_id',\"Item_Classification\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the classification for each movie into the original df dataframe \n",
    "df = df[[\"movie_id\",\"user_id\",\"rating\",\"date\",\"User_Classification\"]].merge(movie,how=\"left\",on=\"movie_id\")\n",
    "del movie\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify each rating based on whether the \"type\" of user matches with the \"type\" of movie\n",
    "# Example: A critical user(Weak_user) rates a movie that is generally dislike(Weak_Movie) as very good(rating >= T1) - This type of movie can be considered as possible noise\n",
    "def classify_rating(row):\n",
    "    user_class = row['User_Classification']\n",
    "    item_rec = row['Item_Classification']\n",
    "    rating = row['rating']\n",
    "\n",
    "    if user_class == 0 and item_rec == 0 and rating >= T1:\n",
    "        return 1\n",
    "    elif user_class == 1 and item_rec == 1 and (rating < T1 or rating >= T2):\n",
    "        return 1\n",
    "    elif user_class == 2 and item_rec == 2 and rating < T2:\n",
    "        return 1\n",
    "    else:\n",
    "      return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify each rating to check if there is noise or not as defined in function above \n",
    "df['possible_noise'] = df.apply(classify_rating, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a reader using surprise library and load dataframe\n",
    "reader = Reader(rating_scale=(1,5))\n",
    "data1 = Dataset.load_from_df(df[[\"user_id\",\"movie_id\",\"rating\"]],reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "   'n_epochs': np.arange(10, 51, 10),\n",
    "   'n_factors' : np.arange(10, 51, 10),\n",
    "   'lr_all': [0.02,0.05,0.1,0.3,0.5,0.7],\n",
    "   'reg_all':[0.02,0.05,0.1,0.3,0.5,0.7]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter tune using 5-fold cv\n",
    "gs = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=5)\n",
    "gs.fit(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print the best parameters\n",
    "print(gs.best_score['rmse'])\n",
    "print(gs.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use best hyperparameter and create model\n",
    "best_factor = gs.best_params['rmse']['n_factors']\n",
    "best_epoch = gs.best_params['rmse']['n_epochs']\n",
    "best_lr_all= gs.best_params['rmse']['lr_all']\n",
    "best_reg_all = gs.best_params['rmse']['reg_all']\n",
    "# nmf_best_param uses SVD - No time to change the names\n",
    "nmf_best_param = SVD(n_factors=best_factor, n_epochs=best_epoch,lr_all=best_lr_all,reg_all=best_reg_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into 2 datasets, train_ and test_\n",
    "# train_ are ratings that are found to have no noise\n",
    "# test_ are ratings that are found to have noise\n",
    "# (Not actually using them for any training/testing)\n",
    "train_ = df[df['possible_noise'] == 0]\n",
    "test_ = df[df['possible_noise'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the non-noisy and noisy ratings\n",
    "non_noisy_ratings = Dataset.load_from_df(train_[[\"user_id\",\"movie_id\",\"rating\"]],reader)\n",
    "noisy_ratings = Dataset.load_from_df(test_[[\"user_id\",\"movie_id\",\"rating\"]],reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict the \"cleaned\" ratings for the possibly noisy ratings\n",
    "nmf_non_noisy_ratings = nmf_best_param.fit(non_noisy_ratings.build_full_trainset())\n",
    "prediction_on_noisy = nmf_best_param.test(noisy_ratings.build_full_trainset().build_testset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the predicted(\"cleaned\") ratings into dataframe and retain the necessary columns only: user_id, movie_id, predicted_rating\n",
    "prediction_df = pd.DataFrame(prediction_on_noisy, columns=[\"user_id\", \"movie_id\", \"actual_rating\", \"predicted_rating\", \"details\"])\n",
    "prediction_df = prediction_df[[\"user_id\", \"movie_id\", \"predicted_rating\"]]\n",
    "prediction_df['predicted_rating'] = prediction_df['predicted_rating'].round(2)\n",
    "prediction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert movie_id and user_id in prediction_df to integers in prediction_df\n",
    "prediction_df['movie_id'] = prediction_df['movie_id'].astype(int)\n",
    "prediction_df['user_id'] = prediction_df['user_id'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert movie_id and user_id in df to integers in prediction_df\n",
    "df['movie_id'] = df['movie_id'].astype(int)\n",
    "df['user_id'] = df['user_id'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge df with prediction_df\n",
    "merged_df = df.merge(prediction_df, on=['user_id', 'movie_id'], how='left')\n",
    "merged_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each possibly noisy rating, if the difference between the predicted(\"cleaned\") rating and the actual rating is more than 1,\n",
    "# we deemed the rating to be actually noisy, and substitute the predicted rating with the actual rating.\n",
    "\n",
    "#If the rating is not noisy, nothing happens and we keep the rating\n",
    "\n",
    "for index, row in merged_df.iterrows():\n",
    "    # Check if 'predicted_rating' is NaN\n",
    "    if pd.isna(row['predicted_rating']):\n",
    "        # Fill 'predicted_rating' with 'rating'\n",
    "        merged_df.at[index, 'predicted_rating'] = row['rating']\n",
    "    else:\n",
    "        # Calculate the absolute difference between 'rating' and 'predicted_rating'\n",
    "        abs_diff = abs(row['rating'] - row['predicted_rating'])\n",
    "\n",
    "        # Check if the absolute difference is greater than 1\n",
    "        if abs_diff < 1:\n",
    "            # Substitute 'predicted_rating' with 'rating'\n",
    "            merged_df.at[index, 'predicted_rating'] = row['rating']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saved the ratings into csv \n",
    "merged_df.to_csv('movielens1m_natural_noise_ratings.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
